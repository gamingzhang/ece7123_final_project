{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YjppAWOfKne8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H7KrKMZ6GUCL"
      },
      "outputs": [],
      "source": [
        "# Configuration for evolution algorithm\n",
        "\n",
        "population_size = 20 # population size\n",
        "numbers_of_generation = 10 # numbers of generation\n",
        "init_epoches = 10 # numbers of epoches we train the model during the evoluation\n",
        "fully_epoches = 100 # numbers of epoches we train the best model\n",
        "part1_min = 7 # minimal size of part1\n",
        "part1_max = 15 # maximum size of part1 \n",
        "kernel_max = 256 # maximum kernel for conv layer\n",
        "add_conv_probability = 0.5 # The probability of adding conv instead of pool during the initialization\n",
        "add_max_pool_probability = 0.8 # The probability of adding maxPool instead of AvgPool during the initialization\n",
        "mutation_size = population_size // 2 # numbers of new individuals after mutation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuD9hEsA6b-W",
        "outputId": "c326f237-92d0-4f8a-d140-b52445800ea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Define hyper-parameters for training\n",
        "batch_size = 64 \n",
        "learning_rate = 1e-2\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(epochs, net):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)  \n",
        "  net = net.to(device)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      for i, (images, labels) in enumerate(train_loader):\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "          outputs = net(images)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "      correct = 0\n",
        "      total = 0\n",
        "      with torch.no_grad():\n",
        "          for images, labels in test_loader:\n",
        "              images, labels = images.to(device), labels.to(device)\n",
        "              outputs = net(images)\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "              total += labels.size(0)\n",
        "              correct += (predicted == labels).sum().item()\n",
        "\n",
        "      print('Epoch: {}/{}, Test Accuracy: {:.2f}'.format(epoch+1, epochs, correct/total))\n",
        "  \n",
        "  return correct / total\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n"
      ],
      "metadata": {
        "id": "qvGRngGpdrvP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "s2F3Nfp1C6-o"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "0 - Conv2d\n",
        "1 - ReLU\n",
        "2 - MaxPool2d\n",
        "3 - AvgPool2d\n",
        "4 - Linear\n",
        "5 - Droupout\n",
        "'''\n",
        "\n",
        "class Individual:\n",
        "  def __init__(self, part1, part2):\n",
        "    # Part1 only contains Conv, Pool, and ReLU\n",
        "    self.part1 = part1\n",
        "    # Part2 only contains Linear, Droupout, and ReLU\n",
        "    self.part2 = part2\n",
        "    self.score = {\n",
        "        \"accuracy\": 0,\n",
        "        \"parameters\": 0\n",
        "    }\n",
        "\n",
        "  def fill_score(self):\n",
        "    torch.cuda.empty_cache()\n",
        "    model = self.decodeCNN()\n",
        "    # self.score['accuracy'] = train_model(init_epoches, model)\n",
        "    self.score['accuracy'] = random.randint(1, 99)\n",
        "    self.score['parameters'] = count_parameters(model)\n",
        "    model = model.to(device)\n",
        "    # summary(model, (3, 32, 32))\n",
        "    del model\n",
        "    torch.cuda.empty_cache()\n",
        "  \n",
        "\n",
        "  def transferToLayer(self, args):\n",
        "    # After conv, the image size remains the same\n",
        "    mapping = {\n",
        "        1: 0, # 1x1 kernel size -> padding = 0\n",
        "        3: 1, # 3x3 kernel size -> padding = 1\n",
        "        5: 2, # 5x5 kernel size -> padding = 2\n",
        "        7: 3, # 7x7 kernel size -> padding = 3\n",
        "    }\n",
        "    layer_type = args[0]\n",
        "    if layer_type == 0:\n",
        "      return nn.Conv2d(in_channels=args[1], out_channels=args[2], kernel_size=args[3], padding=mapping[args[3]])\n",
        "    elif layer_type == 1:\n",
        "      return nn.ReLU()\n",
        "    elif layer_type == 2:\n",
        "      return nn.MaxPool2d(2, 2)\n",
        "    elif layer_type == 3:\n",
        "      return nn.AvgPool2d(2, 2)\n",
        "    elif layer_type == 4:\n",
        "      return nn.Linear(args[1], args[2])\n",
        "    elif layer_type == 5:\n",
        "      return nn.Dropout()\n",
        "\n",
        "  def decodeCNN(self):\n",
        "    return nn.Sequential(\n",
        "        *map(self.transferToLayer, self.part1),\n",
        "        nn.Flatten(),\n",
        "        *map(self.transferToLayer, self.part2),\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_kernel_size():\n",
        "  # we only use three types of kernels\n",
        "  # 1x1 3x3 5x5\n",
        "  return random.choice([1, 3, 5])\n"
      ],
      "metadata": {
        "id": "Xd6UjgD6e1N1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vbIQf7I2CWNL"
      },
      "outputs": [],
      "source": [
        "def initialization(size):\n",
        "  population = []\n",
        "  \n",
        "  for _ in range(size):\n",
        "    part1 = []\n",
        "    part2 = []\n",
        "    output_size = 32 # CIFAR10: 32x32\n",
        "    p1_length = random.randint(part1_min, part1_max)\n",
        "\n",
        "    # First layer must be conv\n",
        "    prev_out_channels = random.randint(5, 12)\n",
        "    part1.extend([\n",
        "        (0, 3, prev_out_channels, get_random_kernel_size()), # Conv\n",
        "        (1,) # ReLU\n",
        "    ])\n",
        "\n",
        "    # Part1\n",
        "    for _ in range(2, p1_length + 1):\n",
        "      if random.random() < add_conv_probability:\n",
        "        # Add Conv\n",
        "        cur_out_channels = random.randint(prev_out_channels, kernel_max)\n",
        "        part1.extend([\n",
        "            (0, prev_out_channels, cur_out_channels, get_random_kernel_size()),\n",
        "            (1,)\n",
        "        ])\n",
        "        prev_out_channels = cur_out_channels\n",
        "      else:\n",
        "        # Add Pool\n",
        "        # We can only add a maximum of 4 pool layers\n",
        "        # For each pooling layer, the image size is reduced to half of the original size\n",
        "        # 32 -> 16 -> 8 -> 4 -> 2 \n",
        "        if output_size == 2:\n",
        "          continue \n",
        "        if random.random() < add_max_pool_probability: # TODO 50% add maxPool, 50% add avgPool\n",
        "          # add MaxPool\n",
        "          part1.append((2,))\n",
        "        else:\n",
        "          # AvgPool\n",
        "          part1.append((3,))\n",
        "        output_size //= 2\n",
        "\n",
        "    # Part2  \n",
        "    prev_features = prev_out_channels * output_size * output_size \n",
        "    \n",
        "    part2.extend([\n",
        "          (5, ), \n",
        "          (4, prev_features, max(10, prev_features // 2)),\n",
        "          (1, ),\n",
        "          (5, ),\n",
        "          (4, max(10, prev_features // 2), max(10, prev_features // 4)),\n",
        "          (1, ),\n",
        "          (4, max(10, prev_features // 4), 10),\n",
        "    ])\n",
        "          \n",
        "    population.append(Individual(part1, part2))\n",
        "\n",
        "  for individual in population:\n",
        "    individual.fill_score()\n",
        "    \n",
        "  return population\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VOWyJrxBGPBy"
      },
      "outputs": [],
      "source": [
        "from itertools import zip_longest \n",
        "\n",
        "\n",
        "def mutation(population):\n",
        "  best = 5\n",
        "  next_generation = []\n",
        "  part1Set = set()\n",
        "\n",
        "  while len(next_generation) < mutation_size:\n",
        "    best_idx = random.randint(0, best - 1)\n",
        "    best_individual = population[best_idx]\n",
        "\n",
        "    r1 = random.randint(0, len(population) - 1)\n",
        "    while r1 == best_idx:\n",
        "      r1 = random.randint(0, len(population) - 1)\n",
        "\n",
        "    r2 = random.randint(0, len(population) - 1)\n",
        "    while r2 in (r1, best_idx):\n",
        "      r2 = random.randint(0, len(population) - 1)\n",
        "    \n",
        "    r1_minus_r2 = differentiate(population[r1], population[r2])\n",
        "    new_individual = merge(best_individual, r1_minus_r2)\n",
        "    if tuple(new_individual.part1) in part1Set:\n",
        "      continue\n",
        "    part1Set.add(tuple(new_individual.part1))\n",
        "    next_generation.append(new_individual)\n",
        "    \n",
        "  \n",
        "  for individual in next_generation:\n",
        "    individual.fill_score()\n",
        "  \n",
        "  return next_generation\n",
        "    \n",
        "    \n",
        "def differentiate(ind1, ind2):\n",
        "  add_to_best = []\n",
        "  p1 = p2 = 0\n",
        "  # Remove ReLU\n",
        "  seq1 = [x for x in ind1.part1 if x[0] != 1]\n",
        "  seq2 = [x for x in ind2.part1 if x[0] != 1]\n",
        "\n",
        "  while p1 < len(seq1) or p2 < len(seq2):\n",
        "    if p1 == len(seq1):\n",
        "      add_to_best.append(seq2[p2])\n",
        "      p2 += 1\n",
        "      continue\n",
        "    if p2 == len(seq2):\n",
        "      add_to_best.append(seq1[p1])\n",
        "      p1 += 1\n",
        "      continue\n",
        "    if seq1[p1][0] == seq2[p2][0]:\n",
        "      add_to_best.append((-1,)) # -1 represents \"remain the smae\"\n",
        "      p1 += 1\n",
        "      p2 += 1\n",
        "    else:\n",
        "      add_to_best.append(seq1[p1])\n",
        "      p1 += 1\n",
        "      p2 += 1\n",
        "      \n",
        "  return add_to_best\n",
        "\n",
        "\n",
        "\n",
        "def merge(best_individual, r1_minus_r2):\n",
        "  new_part1 = []\n",
        "  seq = [x for x in best_individual.part1 if x[0] != 1] # Remove ReLU\n",
        "  count_pool = 0\n",
        "  p1 = p2 = 0\n",
        "  in_channels = 3\n",
        "\n",
        " \n",
        "  while p1 < len(seq):\n",
        "      if p2 == len(r1_minus_r2):\n",
        "          new_part1.append(seq[p1])\n",
        "          p1 += 1\n",
        "      elif r1_minus_r2[p2][0] == -1:\n",
        "          new_part1.append(seq[p1])\n",
        "          p1 += 1\n",
        "          p2 += 1\n",
        "      else:\n",
        "          new_part1.append(r1_minus_r2[p2])\n",
        "          p1 += 1\n",
        "          p2 += 1\n",
        "\n",
        "      if new_part1[-1][0] == 0:\n",
        "          replace = (new_part1[-1][0], in_channels, new_part1[-1][2], new_part1[-1][3])\n",
        "          in_channels = replace[2]\n",
        "          new_part1.pop()\n",
        "          new_part1.extend([replace, (1, )])\n",
        "      elif new_part1[-1][0] in (2, 3):\n",
        "          count_pool += 1\n",
        "          if count_pool > 4:\n",
        "              new_part1.pop()\n",
        "              count_pool -= 1\n",
        "              \n",
        "  features = int(in_channels * (32 * (1 / 2)**count_pool) * (32 * (1 / 2)**count_pool))\n",
        "  new_part2 = [\n",
        "      (5, ), \n",
        "      (4, features, max(10, features // 2)),\n",
        "      (1, ),\n",
        "      (5, ),\n",
        "      (4, max(10, features // 2), max(10, features // 4)),\n",
        "      (1, ),\n",
        "      (4, max(10, features // 4), 10),\n",
        "  ]\n",
        "  \n",
        "  return Individual(new_part1, new_part2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_score(err_max, err_min, para_max, para_min, err, para):\n",
        "  # Normalization\n",
        "  err = (err - err_min) / (err_max - err_min)\n",
        "  para = (para - para_min) / (para_max - para_min)\n",
        "  score = 0.7 * err + 0.3 * para\n",
        "  return score"
      ],
      "metadata": {
        "id": "dj79pV7GIy9t"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KOPz--iiEMkT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialization\n",
        "population = initialization(population_size)\n",
        "err_max = 1 - min(x.score['accuracy'] for x in population)\n",
        "err_min = 1 - max(x.score['accuracy'] for x in population)\n",
        "para_max = max(x.score['parameters'] for x in population)\n",
        "para_min = min(x.score['parameters'] for x in population)\n",
        "population.sort(key=lambda x: get_score(err_max, err_min, para_max, para_min, 1 - x.score['accuracy'], x.score['parameters']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QI5L0qqDENJu"
      },
      "outputs": [],
      "source": [
        "for g in range(2, numbers_of_generation):\n",
        "  # Mutation\n",
        "  new_population = mutation(population)\n",
        "  population.extend(new_population)\n",
        "  err_max = 1 - min(x.score['accuracy'] for x in population)\n",
        "  err_min = 1 - max(x.score['accuracy'] for x in population)\n",
        "  para_max = max(x.score['parameters'] for x in population)\n",
        "  para_min = min(x.score['parameters'] for x in population)\n",
        "  population.sort(key=lambda x: get_score(err_max, err_min, para_max, para_min, 1 - x.score['accuracy'], x.score['parameters']))\n",
        "  population = population[:population_size]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fully train the best CNN\n",
        "best_individual = population[0]\n",
        "train_model(fully_epoches, best_individual.decodeCNN())"
      ],
      "metadata": {
        "id": "4yJGigYgpZr5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "outputId": "0305c8ea-8c0e-47a1-dcc1-bc014e771e86"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/100, Test Accuracy: 0.11\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-74a6c6df40dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# fully train the best CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbest_individual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfully_epoches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_individual\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecodeCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-bf93615723a5>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, net)\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}